{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a34d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9a188c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b57f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, TimeDistributed, concatenate, Flatten, Lambda, LSTM, Convolution2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4153bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.random.set_seed(2345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33cd54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(0,10,size=[3000,100,18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4758d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/data/cash_data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a4f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"C:/data/cash_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b5da767",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"C:/data/cash_data_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dec73cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>cash</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>425814</td>\n",
       "      <td>[[[0.14583333 0.08602151 0.06976744 ... 0.    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>456162</td>\n",
       "      <td>[[[0.13541667 0.06451613 0.01162791 ... 0.    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>134978</td>\n",
       "      <td>[[[0.83333333 0.04301075 0.         ... 0.    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>318952</td>\n",
       "      <td>[[[0.77083333 0.10752688 0.03488372 ... 0.    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>361264</td>\n",
       "      <td>[[[0.02083333 0.06451613 0.04651163 ... 0.    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246004</th>\n",
       "      <td>246004</td>\n",
       "      <td>242114</td>\n",
       "      <td>[[[0.16666667 0.25806452 0.27906977 ... 0.    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246005</th>\n",
       "      <td>246005</td>\n",
       "      <td>452374</td>\n",
       "      <td>[[[0.38541667 0.10752688 0.01162791 ... 0.    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246006</th>\n",
       "      <td>246006</td>\n",
       "      <td>276545</td>\n",
       "      <td>[[[0.09375    0.12903226 0.10465116 ... 0.    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246007</th>\n",
       "      <td>246007</td>\n",
       "      <td>236776</td>\n",
       "      <td>[[[0.80208333 0.12903226 0.04651163 ... 0.    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246008</th>\n",
       "      <td>246008</td>\n",
       "      <td>454197</td>\n",
       "      <td>[[[0.13541667 0.10752688 0.08139535 ... 0.    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246009 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  SK_ID_CURR  \\\n",
       "0                0      425814   \n",
       "1                1      456162   \n",
       "2                2      134978   \n",
       "3                3      318952   \n",
       "4                4      361264   \n",
       "...            ...         ...   \n",
       "246004      246004      242114   \n",
       "246005      246005      452374   \n",
       "246006      246006      276545   \n",
       "246007      246007      236776   \n",
       "246008      246008      454197   \n",
       "\n",
       "                                                     cash  TARGET  \n",
       "0       [[[0.14583333 0.08602151 0.06976744 ... 0.    ...       1  \n",
       "1       [[[0.13541667 0.06451613 0.01162791 ... 0.    ...       0  \n",
       "2       [[[0.83333333 0.04301075 0.         ... 0.    ...       0  \n",
       "3       [[[0.77083333 0.10752688 0.03488372 ... 0.    ...       0  \n",
       "4       [[[0.02083333 0.06451613 0.04651163 ... 0.    ...       0  \n",
       "...                                                   ...     ...  \n",
       "246004  [[[0.16666667 0.25806452 0.27906977 ... 0.    ...       0  \n",
       "246005  [[[0.38541667 0.10752688 0.01162791 ... 0.    ...       0  \n",
       "246006  [[[0.09375    0.12903226 0.10465116 ... 0.    ...       1  \n",
       "246007  [[[0.80208333 0.12903226 0.04651163 ... 0.    ...       1  \n",
       "246008  [[[0.13541667 0.10752688 0.08139535 ... 0.    ...       0  \n",
       "\n",
       "[246009 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba56151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[\"cash\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c20bfe67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134288,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdcd19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[\"cash\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dcdcb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.TARGET.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7d0df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = valid[\"cash\"]\n",
    "y_valid = valid.TARGET.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "226d2c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246009, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "787c6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后在定义模型\n",
    "model_input = Input(shape=(None,100,18),name = \"cash\")\n",
    "layers_con1 = Convolution2D(filters=8,kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)(model_input)\n",
    "layers_con2 = Convolution2D(filters=8,kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)(layers_con1)\n",
    "layers_max2 = MaxPooling2D(pool_size=[2,2], strides = 2, padding = 'same')(layers_con2)\n",
    "\n",
    "\n",
    "layers_con3 = Convolution2D(filters=16, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)(layers_max2)\n",
    "layers_con4 = Convolution2D(filters=16, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)(layers_con3)\n",
    "layers_max4 = MaxPooling2D(pool_size=[2,2], strides = 2, padding = 'same')(layers_con4)\n",
    "\n",
    "layers_con5 = Convolution2D(filters=32, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)(layers_max4)\n",
    "layers_con6 = Convolution2D(filters=32, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)(layers_con5)\n",
    "layers_max6 = MaxPooling2D(pool_size=[2,2], strides = 2, padding = 'same')(layers_con6)\n",
    "\n",
    "\n",
    "fc1 = Dense(128, activation=\"relu\")(layers_max6)\n",
    "fc2 = Dense(64, activation=\"relu\")(fc1)\n",
    "fc3 = Dense(32, activation=\"relu\")(fc2)\n",
    "fc4 = Dense(1, activation=\"sigmoid\")(fc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9e3aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[model_input], outputs=fc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc3bfffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================第 1 次===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12184\\1848857746.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=================第\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"次===============\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ROC_AUC para iteracion\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" - \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# sgd = SGD(lr = 0.2)\n",
    "adam = Adam(lr = 0.001) # 模型优化可以自己选择\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=64, epochs = 10)\n",
    "\n",
    "# loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics = [\"accuracy\"])\n",
    "for i in range(10):\n",
    "    print(\"=================第\",i+1,\"次===============\")\n",
    "    model.fit(X_train, y_train, batch_size=1024, validation_data=(X_valid, y_valid))\n",
    "    print(\"ROC_AUC para iteracion\",i + 1,\":\", roc_auc_score(y_train, model.predict(X_train)[:, -1]), \" - \", roc_auc_score(y_valid, model.predict(X_valid)[:, -1]))\n",
    "\n",
    "print(\"\\ntest loss\", loss)\n",
    "print(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910cbf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396de806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ba29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173aeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9751682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = layers.Conv2D(8, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l2 = layers.Conv2D(8, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l3 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')\n",
    "\n",
    "l4 = layers.Conv2D(16, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l5 = layers.Conv2D(16, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l6 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')\n",
    "\n",
    "l7 = layers.Conv2D(32, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l8 = layers.Conv2D(32, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l9 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')\n",
    "\n",
    "# l10 = layers.Conv2D(512, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "# l11 = layers.Conv2D(512, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "# l12 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')\n",
    "\n",
    "# l13 = layers.Conv2D(512, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "# l14 = layers.Conv2D(512, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "# l15 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc0ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71054f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model.layers)):\n",
    " \n",
    "    print(model.get_layer(index=i).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550013f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0ae273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n",
      "sample: (32, 32, 32, 3) (32,) tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, datasets, Sequential\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "# print(tf.__version__)\n",
    "# print(tf.config.list_physical_devices('GPU') )\n",
    "# print(tf.config.list_physical_devices('CPU'))\n",
    "l1 = layers.Conv2D(64, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l2 = layers.Conv2D(64, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l3 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')\n",
    "\n",
    "l4 = layers.Conv2D(128, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l5 = layers.Conv2D(128, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l6 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')\n",
    "\n",
    "l7 = layers.Conv2D(256, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l8 = layers.Conv2D(256, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l9 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')\n",
    "\n",
    "l10 = layers.Conv2D(512, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l11 = layers.Conv2D(512, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l12 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')\n",
    "\n",
    "l13 = layers.Conv2D(512, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l14 = layers.Conv2D(512, kernel_size = [3,3], padding = \"same\", activation=tf.nn.relu)\n",
    "l15 = layers.MaxPool2D(pool_size=[2,2], strides = 2, padding = 'same')\n",
    "\n",
    "\n",
    "def preprocess(x,y):\n",
    "    x = tf.cast(x, dtype=tf.float32)/255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "(x,y),(x_test, y_test) = datasets.cifar100.load_data()\n",
    "\n",
    "y = tf.squeeze(y, axis=1)\n",
    "y_test = tf.squeeze(y_test, axis=1)\n",
    "print(x.shape, y.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db = train_db.shuffle(1000).map(preprocess).batch(32)\n",
    "\n",
    "\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = train_db.map(preprocess).batch(16)\n",
    "\n",
    "\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print(\"sample:\", sample[0].shape,sample[1].shape,\n",
    "      tf.reduce_min(sample[0]), tf.reduce_max(sample[0]))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # [b, 32,32,3] =》[b,1,1,512]\n",
    "    conv_net = Sequential([l1,l2,l3,l4,l5,l6,l7,l8,l9,l10,l11,l12,l13,l14,l15])\n",
    "    conv_net.build(input_shape = [None, 32, 32, 3])\n",
    "    # x = tf.random.normal([4,32,32,3])\n",
    "    # out = conv_net(x)\n",
    "    # print(out.shape)\n",
    "\n",
    "    fc_net = Sequential([\n",
    "        layers.Dense(256, activation=tf.nn.relu),\n",
    "        layers.Dense(256, activation=tf.nn.relu),\n",
    "        layers.Dense(100, activation = None)\n",
    "    ])\n",
    "\n",
    "    conv_net.build(input_shape = [None, 32, 32, 3])\n",
    "    fc_net.build(input_shape=[None, 512])\n",
    "\n",
    "    # [1,2] + [3,4] = [1,2,3,4]\n",
    "    variables = conv_net.trainable_variables + fc_net.trainable_variables\n",
    "    optimizer = optimizers.Adam(learning_rate =1e-4)\n",
    "\n",
    "    for epoch in range(50):\n",
    "\n",
    "        for step, (x,y) in enumerate(train_db):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                #[b, 32, 32, 3] => [b, 1, 1, 512]\n",
    "                out = conv_net(x)\n",
    "                # flatten\n",
    "                out = tf.reshape(out, [-1, 512])\n",
    "                # [b, 512] = > [b, 100]\n",
    "                logits = fc_net(out)\n",
    "                #\n",
    "                y_onehot = tf.one_hot(y, depth = 100)\n",
    "                loss = tf.keras.losses.categorical_crossentropy(y_onehot, logits, from_logits = True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "\n",
    "            grads = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "            if step % 100 == 0:\n",
    "                print(epoch, step, \"loss\", float(loss))\n",
    "\n",
    "        # total_num = 0\n",
    "        # total_correct = 0\n",
    "        # for x, y in test_db:\n",
    "        #\n",
    "        #     out = conv_net(x)\n",
    "        #     out = tf.reshape(out, [-1, 512])\n",
    "        #     logits = fc_net(out)\n",
    "        #     prob = tf.nn.softmax(logits, axis = 1)\n",
    "        #     pred = tf.argmax(prob, axis = 1)\n",
    "        #     pred = tf.cast(pred, dtype = tf.int32)\n",
    "        #\n",
    "        #     correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "        #     correct = tf.reduce_sum(correct)\n",
    "        #\n",
    "        #     total_num += x.shape[0]\n",
    "        #     total_correct += int(correct)\n",
    "        #\n",
    "        # acc = total_correct / total_num\n",
    "        # print(epoch, \"acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9839f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss 4.605985641479492\n",
      "0 100 loss 4.6050801277160645\n",
      "0 200 loss 4.605642318725586\n",
      "0 300 loss 4.605966567993164\n",
      "0 400 loss 4.588105201721191\n",
      "0 500 loss 4.553032875061035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11332/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11332/1342667960.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[1;31m#[b, 32, 32, 3] => [b, 1, 1, 512]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                 \u001b[1;31m# flatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1056\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1057\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    378\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m--> 420\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    421\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1056\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1057\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    251\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m     name=None):\n\u001b[1;32m-> 1131\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1132\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       return op(\n\u001b[0m\u001b[0;32m   1262\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2713\u001b[0m     \u001b[1;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m     \u001b[1;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m     return gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    922\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    925\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strides\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         \u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ce83a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
